{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNyV+wW2xg0GUKWhwCKqYkw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# 1. import library"],"metadata":{"id":"NbMGMTLBvYfW"}},{"cell_type":"code","source":["# torch\n","import torch\n","import torch.nn as nn\n","import torchvision.datasets as dset # MNIST dataset 사용\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","import torch.optim as optim\n","\n","\n","# matplotlib\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"Ubg2Cpl-vehz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. hyperarameter 설정"],"metadata":{"id":"CuzpHGYDwSf1"}},{"cell_type":"code","source":["# batchsize ,learning rate , num_epoch\n","batch_size = 16\n","learning_rate = 0.002\n","num_epoch = 200"],"metadata":{"id":"n4-C5uokwUvt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 3. model 정의"],"metadata":{"id":"EIHBx_x7xCIO"}},{"cell_type":"code","source":["class myCNN(nn.Module):\n","    def __init__(self):\n","        super(myCNN , self).__init__()\n","        # 1단게 : CNN layer\n","        self.cnn_layer = nn.Sequential(\n","            # convolution + relu --> 1 , 16 , 5(5x5 filter) . padding = 2\n","            nn.Conv2d(1 , 16 , 5 , padding=2), # 28x28x1 --> 28x28x16\n","            nn.ReLU(),\n","\n","            # conv + relu --> 16 , 32 , 5(5x5 filter) , padding = 2\n","            nn.Conv2d(16 , 32 , 5 ,padding=2), # 28x28x16 --> 28x28x32\n","            nn.ReLU(),\n","\n","            # pooling : 28x28 --> 14x14\n","            nn.MaxPool2d(2 , 2),\n","\n","            # conv + relu --> 32 , 64 , 5 , padding = 2\n","            nn.Conv2d(32 , 64 , 5 , padding=2),\n","            nn.ReLU(),\n","\n","            # pooling : 14x14 --> 7x7\n","            nn.MaxPool2d(2 ,2)\n","        ) # cnn_layer의 출력 : 7x7x64\n","\n","        # 2단계 : FC layer (fully_connected)\n","        self.fc_layer = nn.Sequential(\n","            nn.Linear(64*7*7 , 100),\n","            nn.ReLU(),\n","            nn.Linear(100 , 10)\n","        )\n","\n","    def forward (self , x):\n","        out = self.cnn_layer(x) # out : (bach_size) * 7x7x64 3d tensor\n","        out = out.view(batch_size , -1) # out을 펴야됨 out : bach_size x 7x7x64 --> 2d tensor\n","        out = self.fc_layer(out) # fc_layer의 input : 7x7x64x1 1d tensor\n","        # data를 batch_size 단위로 처리한다고 생각\n","        return out\n"],"metadata":{"id":"Ol8ktFAPxELD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 4. data loading"],"metadata":{"id":"8MPKFObz0CAd"}},{"cell_type":"code","source":["mnist_train = dset.MNIST(\"../\" , train=True , transform=transforms.ToTensor(),\n","                         target_transform=None , download=True)\n","mnist_test = dset.MNIST(\"../\", train=False , transform=transforms.ToTensor(),\n","                        target_transform=None , download=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDFQzu_c0EaZ","executionInfo":{"status":"ok","timestamp":1715786216868,"user_tz":-540,"elapsed":11933,"user":{"displayName":"이상민","userId":"17251850509496643037"}},"outputId":"48069c10-9c57-4290-ef4d-9564f9d3caef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../MNIST/raw/train-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 9912422/9912422 [00:03<00:00, 2944593.94it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../MNIST/raw/train-images-idx3-ubyte.gz to ../MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../MNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 28881/28881 [00:00<00:00, 160155.71it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../MNIST/raw/train-labels-idx1-ubyte.gz to ../MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../MNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 1648877/1648877 [00:01<00:00, 1506562.76it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ../MNIST/raw/t10k-images-idx3-ubyte.gz to ../MNIST/raw\n","\n","Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n","Failed to download (trying next):\n","HTTP Error 403: Forbidden\n","\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n","Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../MNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4542/4542 [00:00<00:00, 7601966.79it/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting ../MNIST/raw/t10k-labels-idx1-ubyte.gz to ../MNIST/raw\n","\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"markdown","source":["# 5. data loader 설정"],"metadata":{"id":"6hr1FnEF1BhO"}},{"cell_type":"code","source":["train_loader = torch.utils.data.DataLoader( list(mnist_train)[:batch_size*100] , batch_size=batch_size,\n","                                           shuffle=True , num_workers=2 , drop_last=True)\n","\n","test_loader = torch.utils.data.DataLoader( (mnist_test) , batch_size=batch_size,\n","                                          shuffle=False , num_workers=2 , drop_last=True)"],"metadata":{"id":"nG5rsi4z1Ddr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 6. optimizer 설정"],"metadata":{"id":"WmvydXTf1ryp"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model = myCNN().to(device)\n","\n","loss_func = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters() , lr=learning_rate)"],"metadata":{"id":"0SI31-fM1t9l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 7. accuracy 측정 함수"],"metadata":{"id":"2TsLQiBp2OiM"}},{"cell_type":"code","source":["def EstimateAccuracy (dloader , imodel):\n","    correct = 0\n","    total = 0\n","\n","    for image,label in dloader:\n","        x = Variable(image , volatile=True).to(device) # backpropagation 안해서 volatitle = True\n","        y = Variable(label).to(device)\n","\n","        y_hat = imodel.forward(x)\n","        _ , y_hat_index = torch.max(y_hat , 1)\n","\n","        total += label.size(0)\n","        correct += (y_hat_index == y).sum().float()\n","\n","        print(\"Accuracy : {}\".format(100*correct/total))\n","\n","        return 100*correct/total"],"metadata":{"id":"dTVRcGvi2VG_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 8. 훈련"],"metadata":{"id":"SGHWbh0t2R00"}},{"cell_type":"code","source":["loss_arr = []\n","accu_arr = []\n","\n","for i in range(num_epoch):\n","    for image , label in train_loader:\n","        x = Variable(image).to(device)\n","        y = Variable(label).to(device)\n","\n","        optimizer.zero_grad()\n","        y_hat = model.forward(x)\n","        loss = loss_func(y_hat , y)\n","        loss.backward()\n","        optimizer.step()\n","    if i%10 == 0:\n","        print(i , loss)\n","        accu = EstimateAccuracy(test_loader , model)\n","        loss_arr.append(loss)\n","        accu_arr.append(accu)"],"metadata":{"collapsed":true,"id":"Qk2LKFqV3N82"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 9. 결과 출력"],"metadata":{"id":"j7MGTZoD2TUH"}}]}